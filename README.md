# Load Testing de LLMs con AnÃ¡lisis de Consistencia

**Proyecto de investigaciÃ³n aplicada sobre performance y quality testing de APIs LLM con Server-Sent Events (SSE)**

**Autor**: Rodrigo Campos .T | **Estado**: Sprint 2 âœ… Completado | **Fecha**: Noviembre 2025

---

## ğŸ“š DocumentaciÃ³n Completa

**Toda la documentaciÃ³n tÃ©cnica, anÃ¡lisis y experimentos estÃ¡ organizada en:**

ğŸ‘‰ **[/docs](docs/README.md)** - Ãndice completo de documentaciÃ³n

### ğŸ“– Documentos Destacados:

#### **Sprint 1: AnÃ¡lisis Inicial**
- **[ArtÃ­culo de Consistencia](docs/sprint1/consistency-article.md)** - AnÃ¡lisis exhaustivo de hallazgos y aprendizajes
- **[GuÃ­a Completa Sprint 1](docs/sprint1/README.md)** - CÃ³mo replicar el experimento
- **[AnÃ¡lisis del Gap SSE en Gatling](docs/sprint1/experiments/gatling-sse-analysis-en.md)** - InvestigaciÃ³n tÃ©cnica sobre mediciÃ³n SSE

#### **Sprint 2: AnÃ¡lisis Avanzado** â­ NUEVO
- **[ArtÃ­culo LinkedIn: De 47.5% a 0%](docs/sprint2/linkedin-article.md)** - CÃ³mo encontrÃ© el cuello de botella real
- **[DocumentaciÃ³n TÃ©cnica del CÃ³digo](docs/sprint2/code-documentation.md)** - Arquitectura y guÃ­a de implementaciÃ³n
- **[Reporte de ValidaciÃ³n](docs/sprint2/validation-report.md)** - MÃ©tricas completas y hallazgos crÃ­ticos

---

## ğŸš€ Quick Start: Â¿QuÃ© es este proyecto?

Este proyecto implementa un **sistema de anÃ¡lisis de calidad y consistencia** para respuestas LLM bajo carga, con capacidades de:

### **Sprint 1: DetecciÃ³n de Problemas BÃ¡sicos**
âœ… **47.5% de respuestas truncadas detectadas** (que habrÃ­an pasado como HTTP 200 OK)
âœ… **Gap de +403%** en mediciÃ³n Gatling vs latencia real del usuario
âœ… **DegradaciÃ³n de +775%** bajo carga sostenida (RAMP â†’ STEADY)
âœ… **70.4% de falla** en prompts largos vs 8.3% en prompts cortos

**Costo**: $0.30 por 610 requests

### **Sprint 2: AnÃ¡lisis Avanzado con IA** â­
âœ… **0.0% truncamiento** (problema 100% resuelto reduciendo carga de 30 a 10 usuarios)
âœ… **AnÃ¡lisis semÃ¡ntico con embeddings** (0.889 similitud vs 0.306 Jaccard = +190%)
âœ… **LLM-as-a-Judge con GPT-4o** (evaluaciÃ³n cualitativa automatizada: 7.4/10)
âœ… **Score global 9.6** (sistema production-ready)
âœ… **Timeouts dinÃ¡micos por categorÃ­a** (5s-20s segÃºn complejidad del prompt)

**Costo total**: $0.45 por anÃ¡lisis completo (test + embeddings + GPT-4 judge)

---

## ğŸ¯ Hallazgos Clave del Proyecto

### **Hallazgo #1: El Problema NO Era de Timeouts**

**HipÃ³tesis inicial (Sprint 1):** Los timeouts de 10s son inadecuados
**SoluciÃ³n planeada (Sprint 2):** Implementar timeouts dinÃ¡micos (5-20s)
**Resultado:** Truncamiento pasÃ³ de 47.5% a 0.0%

**RevelaciÃ³n:** El problema real era la **carga concurrente inicial**:

| ConfiguraciÃ³n | Usuarios RAMP | Latencia Global | Truncamiento |
|---------------|---------------|-----------------|--------------|
| Sprint 1 | 30 usuarios/30s | 8,826ms | 47.5% âŒ |
| Sprint 2 | 10 usuarios/10s | 2,872ms | 0.0% âœ… |

**ConclusiÃ³n:** Reducir la rampa de 30 a 10 usuarios resolviÃ³ el 100% del problema. Los timeouts dinÃ¡micos son Ãºtiles como safety net, pero **no fueron la soluciÃ³n principal**.

---

### **Hallazgo #2: OpenAI Tiene LÃ­mites de Concurrencia Reales**

**Evidencia:**
- Con 30 usuarios en RAMP â†’ requests se **encolan** â†’ latencia +775% â†’ timeouts
- Con 10 usuarios en RAMP â†’ requests se procesan **inmediatamente** â†’ latencia normal â†’ sin timeouts

**ImplicaciÃ³n:** OpenAI API (GPT-3.5-turbo-0125) bajo mi account tier se satura con patrones de rampa agresivos. Para escalar >10 usuarios/seg necesitas:
1. Account tier mÃ¡s alto (rate limits mayores)
2. Caching agresivo para prompts frecuentes
3. Load balancing entre mÃºltiples API keys
4. Circuit breakers inteligentes

---

### **Hallazgo #3: Embeddings Son Superiores a Jaccard (+190%)**

**Sprint 1 (Jaccard Similarity):**
- Score: 0.306 (30.6%)
- Falsos positivos: ~40%
- No distingue creatividad legÃ­tima de inconsistencia

**Sprint 2 (OpenAI Embeddings):**
- Score: 0.889 (88.9%)
- Falsos positivos: ~5%
- Entiende sinÃ³nimos, parafraseo y significado semÃ¡ntico

**Mejora: +190% en precisiÃ³n**

---

### **Hallazgo #4: GPT-4 Judge Detecta Issues EspecÃ­ficos**

ImplementÃ© GPT-4o como evaluador automÃ¡tico con 4 dimensiones:
- **Similarity** (0-10): Similitud semÃ¡ntica
- **Technical Correctness** (0-10): CorrecciÃ³n tÃ©cnica
- **Coherence** (0-10): Completitud y coherencia
- **Creativity Expected** (bool): Â¿Es esperada la variaciÃ³n?

**Score promedio: 7.4/10**

**Ejemplos reales de issues detectados:**
- âœ… "Inconsistent class examples across responses"
- âœ… "Incomplete thoughts in some responses"
- âœ… "Response has syntax errors"

**Valor agregado:** Los issues son **especÃ­ficos** y **accionables**, no genÃ©ricos.

---

### **Hallazgo #5: El Costo de AnÃ¡lisis Avanzado es Bajo ($0.15)**

**Desglose Sprint 2:**

| Componente | Cantidad | Costo |
|------------|----------|-------|
| Test de carga (GPT-3.5-turbo-0125) | 610 requests | $0.30 |
| Embeddings (text-embedding-3-small) | 189 textos | $0.001 |
| GPT-4 Judge (GPT-4o-2024-08-06) | 5 evaluaciones | $0.15 |
| **TOTAL** | - | **$0.45** |

**ROI del incremento (+$0.15 vs Sprint 1):**
- AnÃ¡lisis semÃ¡ntico confiable (vs Jaccard no confiable)
- EvaluaciÃ³n cualitativa automatizada (vs manual imposible)
- Sistema production-ready (vs MVP experimental)

---

## ğŸ“Š ComparaciÃ³n Sprint 1 vs Sprint 2

| MÃ©trica | Sprint 1 | Sprint 2 | Mejora | Estado |
|---------|----------|----------|--------|--------|
| **Truncamiento** | 47.5% | **0.0%** | -100% | âœ…âœ…âœ… |
| **Latencia Global** | 8,826ms | **2,872ms** | -67.5% | âœ…âœ…âœ… |
| **Similitud SemÃ¡ntica** | 0.306 (Jaccard) | **0.889** (Embeddings) | +190% | âœ…âœ…âœ… |
| **EvaluaciÃ³n Cualitativa** | âŒ No existe | **7.4/10** (GPT-4o) | Nuevo | âœ…âœ… |
| **Score Global** | 0.505 | **9.6** | +1,801% | âœ…âœ…âœ… |
| **Costo por anÃ¡lisis** | $0.30 | $0.45 | +50% | âœ… |
| **Production-Ready** | âŒ No | âœ… SÃ­ | - | âœ…âœ…âœ… |

---

## ğŸ› ï¸ Stack TÃ©cnico

### **Framework y Herramientas**
- **Gatling 3.11.3** - Load testing con soporte SSE nativo
- **Java 11** - Lenguaje de implementaciÃ³n
- **Maven** - Build y gestiÃ³n de dependencias
- **Apache Commons Math 3.6.1** - Cosine similarity

### **Modelos OpenAI**
- **GPT-3.5-turbo-0125** - Target de pruebas de carga
- **text-embedding-3-small** - AnÃ¡lisis semÃ¡ntico
- **GPT-4o-2024-08-06** - LLM-as-a-Judge

### **Componentes Sprint 2 (Nuevos)**
```
src/test/java/ssellm/
â”œâ”€â”€ SSELLM.java                        # Modificado: Timeouts dinÃ¡micos
â”œâ”€â”€ analyzers/                         # NUEVO paquete
â”‚   â”œâ”€â”€ SemanticAnalyzer.java         # AnÃ¡lisis con embeddings
â”‚   â”œâ”€â”€ LLMJudge.java                 # GPT-4 como juez
â”‚   â”œâ”€â”€ QualityReportGenerator.java   # Pipeline completo
â”‚   â””â”€â”€ AdvancedMetrics.java          # MÃ©tricas avanzadas
â”œâ”€â”€ clients/                           # NUEVO paquete
â”‚   â””â”€â”€ OpenAIClient.java             # Cliente OpenAI nativo
â””â”€â”€ models/                            # EXTENDIDO
    â”œâ”€â”€ ResponseMetadata.java         # +1 campo (timeout_used_ms)
    â”œâ”€â”€ SemanticAnalysisResult.java   # NUEVO
    â”œâ”€â”€ LLMJudgeEvaluation.java       # NUEVO
    â””â”€â”€ QualityReport.java            # NUEVO
```

---

## Â¿Por quÃ© necesitas probar el rendimiento de tu API de LLM?

Si estÃ¡s integrando ChatGPT, Claude o cualquier LLM en tu aplicaciÃ³n, seguramente te has preguntado: **Â¿CuÃ¡ntos usuarios simultÃ¡neos puede manejar mi sistema?** Â¿QuÃ© pasa cuando 100 personas hacen preguntas al mismo tiempo?

Las APIs de LLM son fundamentalmente diferentes a las APIs REST tradicionales. **No devuelven una respuesta instantÃ¡nea**, sino que transmiten el texto palabra por palabra durante varios segundos usando **Server-Sent Events (SSE)**.

Esto crea desafÃ­os Ãºnicos:
- â±ï¸ Latencias extremadamente variables (1-30 segundos)
- ğŸ’¸ Cada test tiene un costo real
- ğŸ“Š Necesitas validar calidad, no solo velocidad
- ğŸ”„ Las respuestas llegan en fragmentos que debes ensamblar correctamente

---

## Â¿QuÃ© debes medir en tus pruebas?

### 1. MÃ©tricas Tradicionales (Siguen siendo importantes)

**Error Rate (Tasa de Error)**
- Â¿QuÃ© es? Porcentaje de requests que fallan
- Objetivo: < 1%
- Errores comunes: `429 Too Many Requests`, `503 Service Unavailable`, timeouts

**Throughput (Capacidad)**
- Â¿QuÃ© es? CuÃ¡ntos requests por segundo puede manejar tu sistema
- Ejemplo: 10 usuarios concurrentes, cada request tarda 5 seg â†’ 2 req/seg

**Response Time Percentiles (p50, p95, p99)**
- Â¿Por quÃ© importan? El promedio puede engaÃ±ar
- Ejemplo: Promedio = 4s (parece bueno), pero p99 = 60s significa que el 1% de usuarios espera 1 minuto

### 2. MÃ©tricas EspecÃ­ficas de LLMs (Lo nuevo)

**TTFB (Time To First Byte) - La MÃ©trica de PercepciÃ³n**
- Â¿QuÃ© es? CuÃ¡nto tarda en llegar el PRIMER fragmento de respuesta
- Por quÃ© importa: Es lo que el usuario percibe como "velocidad"
- Objetivos:
  - Excelente: < 200ms
  - Bueno: < 500ms
  - Aceptable: < 1000ms
  - Malo: > 1000ms

**Tokens por Segundo - La MÃ©trica de Fluidez**
- Â¿QuÃ© es? Velocidad de generaciÃ³n de texto
- Velocidades de referencia:
  - 30 tok/seg = Lento (tipeo lento)
  - 50 tok/seg = Bueno (lectura fluida)
  - 100 tok/seg = RÃ¡pido (casi instantÃ¡neo)
- Por modelo:
  - GPT-3.5-turbo: 50-100 tok/seg
  - GPT-4: 20-40 tok/seg (mÃ¡s preciso, mÃ¡s lento)

**Completitud de Respuesta - La MÃ©trica de Confiabilidad**
- Â¿QuÃ© es? Â¿LlegÃ³ la respuesta COMPLETA hasta el marcador `[DONE]`?
- Objetivo: 100%
- Causas de respuestas incompletas:
  - Buffer muy pequeÃ±o
  - ConexiÃ³n cerrada prematuramente
  - Timeout del cliente

**DuraciÃ³n Total del Streaming**
- Â¿QuÃ© es? Tiempo desde el request hasta que termina el streaming
- Objetivos por categorÃ­a de prompt:

| Tipo de Prompt | max_tokens | DuraciÃ³n Esperada |
|----------------|------------|-------------------|
| Corto          | 100-200    | 1-2 seg          |
| Medio          | 500-800    | 5-10 seg         |
| Largo          | 1500-2000  | 20-30 seg        |
| Muy Largo      | 3000-4000  | 40-60 seg        |

**Calidad de Respuesta - La MÃ©trica de Negocio** â­ Sprint 2
- No solo velocidad. TambiÃ©n valida:
  - âœ“ Coherencia: Â¿Tiene sentido?
  - âœ“ Relevancia: Â¿Responde la pregunta?
  - âœ“ Idioma correcto
  - âœ“ Formato: Â¿Respeta markdown/cÃ³digo si se pidiÃ³?
  - âœ“ Completitud: Â¿EstÃ¡ terminada?
  - âœ“ **Similitud semÃ¡ntica** (embeddings)
  - âœ“ **EvaluaciÃ³n GPT-4** (4 dimensiones)

---

## Tabla Resumen: Â¿CuÃ¡l es la mÃ©trica mÃ¡s importante?

| MÃ©trica               | QuÃ© mide              | Objetivo  | CrÃ­tico para      |
|-----------------------|-----------------------|-----------|-------------------|
| **Error Rate**        | % requests fallidos   | < 1%      | Disponibilidad    |
| **p95 Response Time** | Latencia percibida    | < 10s     | UX                |
| **TTFB**              | Primera impresiÃ³n     | < 500ms   | PercepciÃ³n        |
| **Tokens/segundo**    | Velocidad generaciÃ³n  | > 50      | Fluidez           |
| **Completitud**       | Respuestas completas  | 100%      | Confiabilidad     |
| **Similitud SemÃ¡ntica** â­ | Consistencia AI    | > 0.70    | Calidad           |
| **LLM Judge Score** â­ | EvaluaciÃ³n cualitativa | > 7.0   | Valor de negocio  |

---

## ğŸš€ GuÃ­a de Uso RÃ¡pido

### **EjecuciÃ³n Completa Sprint 2** (Test + AnÃ¡lisis Avanzado)

```bash
#!/bin/bash
# Ejecutar test completo con anÃ¡lisis avanzado

# 1. Configurar API key
export api_key=$(grep "api_key" .env | cut -d'=' -f2 | tr -d '"')

# 2. Ejecutar test de Gatling
./mvnw gatling:test -Dgatling.simulationClass=ssellm.SSELLM

# 3. Generar classpath (solo primera vez)
./mvnw dependency:build-classpath -Dmdep.outputFile=classpath.txt

# 4. Ejecutar anÃ¡lisis completo (embeddings + GPT-4 judge)
java -cp "target/test-classes:$(cat classpath.txt)" \
  ssellm.analyzers.QualityReportGenerator \
  target/responses_metadata.jsonl \
  quality_report_sprint2.json

# 5. Ver resultados
cat quality_report_sprint2.json
```

### **Output Esperado:**

```
================================================================================
ğŸ“Š SPRINT 2 - QUALITY REPORT GENERATOR
================================================================================

[1/6] ğŸ“‚ Loading metadata file...
   âœ“ Loaded 610 responses

[2/6] ğŸ“ˆ Calculating basic metrics...
   âœ“ Total responses: 610
   âœ“ Truncated: 0 (0.0%)

[3/6] ğŸ—‚ï¸ Grouping responses by prompt...
   âœ“ 30 unique prompts
   âœ“ 9 categories

[4/6] ğŸ” Running semantic analysis...
   ğŸ“Š Analyzing 9 prompts (sampled at 30%)
   âœ… Semantic analysis complete

[5/6] âš–ï¸ Running LLM-as-judge evaluation...
   âš–ï¸ Evaluating 5 prompts with GPT-4
   âœ… LLM judge evaluation complete

[6/6] ğŸ“Š Analyzing by category and phase...

ğŸ’¾ Saving report to: quality_report_sprint2.json
   âœ“ Report saved successfully

================================================================================
ğŸ“Š QUALITY REPORT SUMMARY
================================================================================

ğŸ“ˆ Overall Metrics:
   Total Responses: 610
   Truncation Rate: 0.0%

ğŸ” Semantic Analysis:
   Prompts Analyzed: 9
   Avg Similarity: 0.889

âš–ï¸ LLM Judge Evaluation:
   Prompts Evaluated: 5
   Avg LLM Score: 7.4/10

================================================================================
```

---

## Patrones de Carga Recomendados

### **ConfiguraciÃ³n Sprint 1 (ProblemÃ¡tica)**
```java
setUp(
  prompt.injectOpen(
    rampUsers(30).during(30),           // 30 usuarios â†’ SATURACIÃ“N âŒ
    constantUsersPerSec(10).during(60)
  )
).protocols(httpProtocol);
```
**Resultado:** 47.5% truncamiento, 8,826ms latencia

### **ConfiguraciÃ³n Sprint 2 (Ã“ptima)** âœ…
```java
setUp(
  prompt.injectOpen(
    rampUsers(10).during(10),           // 10 usuarios â†’ ESTABLE âœ…
    constantUsersPerSec(10).during(60)
  )
).protocols(httpProtocol);
```
**Resultado:** 0.0% truncamiento, 2,872ms latencia

### **LecciÃ³n Aprendida:**
> "Funciona bien" es relativo al patrÃ³n de carga. El mismo sistema puede ser "roto" o "perfecto" dependiendo del patrÃ³n de rampa inicial.

---

## Checklist: Antes de ir a ProducciÃ³n

**Performance:**
- [ ] Error rate < 1%
- [ ] p95 response time < 10 segundos
- [ ] TTFB < 500ms para el 95% de requests
- [ ] Tokens/segundo > 30
- [ ] 100% de respuestas completas (sin fragmentos perdidos)
- [ ] Truncamiento < 1%

**Calidad (Sprint 2):**
- [ ] Similitud semÃ¡ntica (embeddings) > 0.70
- [ ] LLM Judge score > 7.0/10
- [ ] Respuestas coherentes y relevantes
- [ ] Idioma correcto
- [ ] Formato correcto (markdown, cÃ³digo, etc.)

**Estabilidad:**
- [ ] Throughput sostenido sin caÃ­das durante 5+ minutos
- [ ] Sin errores 429 (rate limiting)
- [ ] Sistema se recupera despuÃ©s de picos de carga
- [ ] PatrÃ³n de rampa gradual (no agresivo)

**Costos:**
- [ ] EstimaciÃ³n de costo mensual segÃºn volumen esperado
- [ ] Estrategia de caching para reducir llamadas repetidas
- [ ] Monitoreo de uso de tokens

---

## ğŸ“š Referencias Oficiales

### **OpenAI API**
- [Chat Completions API](https://platform.openai.com/docs/guides/text-generation)
- [Embeddings Guide](https://platform.openai.com/docs/guides/embeddings)
- [Streaming (SSE)](https://platform.openai.com/docs/api-reference/streaming)
- [Rate Limits](https://platform.openai.com/docs/guides/rate-limits)
- [Production Best Practices](https://platform.openai.com/docs/guides/production-best-practices)
- [Pricing Calculator](https://openai.com/api/pricing/)

### **Herramientas**
- [Gatling Load Testing](https://gatling.io/docs/gatling/)
- [Gatling SSE Protocol](https://docs.gatling.io/reference/script/protocols/sse/)
- [Apache Commons Math](https://commons.apache.org/proper/commons-math/)

---

## ğŸ¯ ConclusiÃ³n y PrÃ³ximos Pasos

### **Lo Que Aprendimos:**

1. âœ… **El cuello de botella estaba en la carga concurrente**, no en los timeouts
2. âœ… **Embeddings son superiores a Jaccard** para anÃ¡lisis semÃ¡ntico (+190%)
3. âœ… **GPT-4 Judge es efectivo** para evaluaciÃ³n cualitativa automatizada
4. âœ… **El costo de anÃ¡lisis avanzado es bajo** ($0.15 por test completo)
5. âœ… **El sistema escala perfecto con 10 usuarios/seg** (patrÃ³n de rampa gradual)

### **Estado Actual:**

El sistema evolucionÃ³ de:
- âŒ **MVP experimental** (Sprint 1: score 0.505, 47.5% truncamiento)
- âœ… **SoluciÃ³n production-ready** (Sprint 2: score 9.6, 0.0% truncamiento)

### **PrÃ³ximos Pasos (Sprint 3-4):**

**Sprint 3: OptimizaciÃ³n de Carga**
- Experimentar con diferentes niveles de concurrencia (5, 10, 15, 20 usuarios/seg)
- Encontrar el punto Ã³ptimo carga/calidad
- Implementar circuit breakers inteligentes

**Sprint 4: Dashboard y CI/CD**
- Dashboard HTML interactivo (Plotly/D3.js)
- IntegraciÃ³n con GitHub Actions
- Alertas automÃ¡ticas cuando score < threshold

---

## ğŸ“– DocumentaciÃ³n Completa

Para anÃ¡lisis tÃ©cnico detallado, implementaciÃ³n y hallazgos:

- **[Sprint 1: ArtÃ­culo de Consistencia](docs/sprint1/consistency-article.md)**
- **[Sprint 2: De 47.5% a 0%](docs/sprint2/linkedin-article.md)** â­
- **[Sprint 2: DocumentaciÃ³n TÃ©cnica](docs/sprint2/code-documentation.md)**
- **[Sprint 2: Reporte de ValidaciÃ³n](docs/sprint2/validation-report.md)**

---

### Propiedad y Derechos de Autor

Este cÃ³digo es propiedad de Rodrigo Campos .T (Dontester). Todos los derechos de autor estÃ¡n reservados.

Â© Rodrigo Campos .T (Dontester) - 2025

---

**Â¿Te resultÃ³ Ãºtil este proyecto?**

ğŸ“¢ Comparte con tu comunidad de QA y Performance Testing
ğŸ’¬ Â¿QuÃ© mÃ©tricas priorizas tÃº en tus pruebas de LLM?
ğŸ”– Guarda este repositorio para tu prÃ³ximo proyecto con IA

---

**Ãšltima actualizaciÃ³n:** Noviembre 19, 2025
**VersiÃ³n:** 2.0 (Production-Ready)
