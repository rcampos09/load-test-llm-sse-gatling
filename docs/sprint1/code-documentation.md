# ğŸ“š DocumentaciÃ³n TÃ©cnica del CÃ³digo - Sprint 1

**Ãšltima actualizaciÃ³n**: Octubre 2025
**Autor**: Ricardo Campos
**VersiÃ³n**: 1.0 (Sprint 1)

---

## ğŸ¯ VisiÃ³n General del Sistema

Este proyecto implementa un sistema de **load testing para APIs LLM con Server-Sent Events (SSE)** que incluye:

1. **GeneraciÃ³n de carga** usando Gatling (SSELLM.java)
2. **Captura de metadata completa** en tiempo real (JSONL format)
3. **AgregaciÃ³n de respuestas** por mÃºltiples dimensiones (ResponseAggregator.java)
4. **AnÃ¡lisis de consistencia** sin LLM externo (ConsistencyAnalyzer.java)
5. **Modelo de datos rico** con 16 campos (ResponseMetadata.java)

---

## ğŸ“ Arquitectura del Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      SSELLM.java (Gatling)                      â”‚
â”‚                  Load Test + SSE Processing                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â”œâ”€> Genera requests al LLM (SSE)
                        â”œâ”€> Captura chunks en tiempo real
                        â”œâ”€> Calcula mÃ©tricas (TTFT, response time, truncation)
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              target/responses_metadata.jsonl                    â”‚
â”‚         16 campos Ã— 610 responses = Metadata completa           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ResponseAggregator.java                            â”‚
â”‚     Agrupa respuestas por: prompt, category, phase             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ConsistencyAnalyzer.java                           â”‚
â”‚   Analiza 5 dimensiones: completeness, structural, semantic,   â”‚
â”‚            temporal, category â†’ Score global 0-1                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
        target/consistency_analysis.json (Report final)
```

---

## ğŸ“ Estructura de Archivos del Proyecto

```
src/test/java/ssellm/
â”œâ”€â”€ SSELLM.java                     # SimulaciÃ³n Gatling + captura SSE
â”œâ”€â”€ ResponseAggregator.java         # AgregaciÃ³n de respuestas
â”œâ”€â”€ ConsistencyAnalyzer.java        # AnÃ¡lisis de 5 dimensiones
â””â”€â”€ models/
    â””â”€â”€ ResponseMetadata.java       # Modelo de datos (16 campos)

target/
â”œâ”€â”€ responses_metadata.jsonl        # 610 lÃ­neas JSONL (1 por response)
â”œâ”€â”€ responses_by_prompt.json        # AgrupaciÃ³n por prompt
â”œâ”€â”€ consistency_analysis.json       # Reporte de anÃ¡lisis completo
â”œâ”€â”€ llm_response.txt               # Formato legible para debugging
â””â”€â”€ sse_chunks.txt                 # Chunks SSE raw (debugging)
```

---

## ğŸ“¦ Clase: `ResponseMetadata.java`

**UbicaciÃ³n**: `src/test/java/ssellm/models/ResponseMetadata.java`

**PropÃ³sito**: Modelo de datos que representa **una respuesta LLM completa** con toda su metadata.

### ğŸ” Campos (16 en total)

#### **Identificadores**
```java
@JsonProperty("session_id")
private String sessionId;           // userId-scenario (ej: "1-Scenario")

@JsonProperty("chunk_id")
private String chunkId;              // ID del SSE chunk (ej: "chatcmpl-xyz")

@JsonProperty("user_id")
private long userId;                 // Gatling user ID (1-10)
```

#### **Contexto del Test**
```java
@JsonProperty("category")
private String category;             // "short", "medium", "long", "creative", "technical"

@JsonProperty("prompt")
private String prompt;               // Texto del prompt enviado

@JsonProperty("max_tokens")
private int maxTokens;               // LÃ­mite de tokens configurado

@JsonProperty("temperature")
private double temperature;          // ParÃ¡metro de creatividad (0.7)
```

#### **Contenido de la Respuesta**
```java
@JsonProperty("response")
private String response;             // Texto completo de la respuesta

@JsonProperty("response_length")
private int responseLength;          // Longitud en caracteres (auto-calculado)
```

#### **MÃ©tricas de Performance**
```java
@JsonProperty("timestamp")
private Instant timestamp;           // Momento de completion (ISO-8601)

@JsonProperty("response_time_ms")
private long responseTimeMs;         // Latencia end-to-end (requestStart â†’ [DONE])

@JsonProperty("ttft_ms")
private long ttftMs;                 // Time To First Token (requestStart â†’ primer chunk con content)

@JsonProperty("total_chunks")
private int totalChunks;             // Cantidad de chunks SSE recibidos
```

#### **Indicadores de Calidad**
```java
@JsonProperty("truncated")
private boolean truncated;           // true si la respuesta estÃ¡ incompleta

@JsonProperty("truncation_reason")
private String truncationReason;     // "NONE", "TIMEOUT", "BUFFER_OVERFLOW"

@JsonProperty("test_phase")
private String testPhase;            // "RAMP" (primeros 10s) o "STEADY" (60s siguientes)
```

### ğŸ—ï¸ Builder Pattern

La clase implementa el **Builder pattern** para construcciÃ³n fluida:

```java
ResponseMetadata metadata = ResponseMetadata.builder()
    .sessionId("1-Scenario")
    .chunkId("chatcmpl-xyz")
    .userId(1L)
    .category("short")
    .prompt("Explica quÃ© es Java")
    .maxTokens(150)
    .temperature(0.7)
    .response("Java es un lenguaje de programaciÃ³n...")
    .timestamp(Instant.now())
    .responseTimeMs(1250L)
    .ttftMs(320L)
    .totalChunks(15)
    .truncated(false)
    .truncationReason("NONE")
    .testPhase("STEADY")
    .build();
```

### ğŸ“‹ MÃ©todos Importantes

- **`setResponse(String response)`**: Actualiza respuesta y calcula `responseLength` automÃ¡ticamente
- **`setTruncationReason(String reason)`**: Si reason != "NONE", marca `truncated = true` automÃ¡ticamente
- **`toString()`**: Formato compacto para logging

### ğŸ“Š Ejemplo de JSON Serializado

```json
{
  "session_id": "1-Scenario",
  "chunk_id": "chatcmpl-AQWoV6",
  "user_id": 1,
  "category": "short",
  "prompt": "Explica quÃ© es Java en una oraciÃ³n",
  "max_tokens": 150,
  "temperature": 0.7,
  "response": "Java es un lenguaje de programaciÃ³n orientado a objetos...",
  "response_length": 245,
  "timestamp": "2025-10-26T10:15:32.123Z",
  "response_time_ms": 1250,
  "ttft_ms": 320,
  "total_chunks": 15,
  "truncated": false,
  "truncation_reason": "NONE",
  "test_phase": "STEADY"
}
```

---

## ğŸš€ Clase: `SSELLM.java`

**UbicaciÃ³n**: `src/test/java/ssellm/SSELLM.java`

**PropÃ³sito**: SimulaciÃ³n Gatling que ejecuta el load test y captura **toda la metadata en tiempo real**.

### ğŸ”§ ConfiguraciÃ³n Principal

```java
String api_key = System.getenv("api_key");  // API key de OpenAI desde variable de entorno

// Archivos de salida
Path ruta = Path.of("target/sse_chunks.txt");              // Raw SSE chunks (debugging)
Path rutaRespuesta = Path.of("target/llm_response.txt");   // Formato legible
Path rutaMetadata = Path.of("target/responses_metadata.jsonl");  // JSONL (principal)

// Feeder CSV para prompts
FeederBuilder<String> promptFeeder = csv("prompts.csv").circular();

// ObjectMapper para serializaciÃ³n JSON
ObjectMapper objectMapper = new ObjectMapper()
    .registerModule(new JavaTimeModule())
    .disable(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS);
```

### ğŸ“ DetecciÃ³n de Fase del Test

```java
long testStartTime = System.currentTimeMillis();
long rampDuration = 10000; // 10 segundos RAMP

// Durante el procesamiento de cada response:
long timeSinceTestStart = currentTime - testStartTime;
String testPhase = timeSinceTestStart < rampDuration ? "RAMP" : "STEADY";
```

**LÃ³gica**:
- Primeros 10 segundos â†’ `RAMP`
- DespuÃ©s de 10 segundos â†’ `STEADY`

### ğŸŒ Protocolo HTTP SSE

```java
HttpProtocolBuilder httpProtocol = http
    .baseUrl("https://api.openai.com/v1/chat")
    .sseUnmatchedInboundMessageBufferSize(100);  // Buffer para chunks SSE
```

### ğŸ­ Escenario Gatling

```java
ScenarioBuilder prompt = scenario("Scenario")
    .feed(promptFeeder)  // Inyecta: category, prompt, max_tokens, temperature
    .exec(
        sse("Connect to LLM - #{category}")
            .post("/completions")
            .header("Authorization", "Bearer " + api_key)
            .header("Content-Type", "application/json")
            .body(StringBody("{...}"))  // Payload JSON con prompt
            .asJson()
    )
    .asLongAs("#{stop.isUndefined()}").on(  // Loop hasta recibir [DONE]
        sse.processUnmatchedMessages((messages, session) -> {
            // âš™ï¸ PROCESAMIENTO DE CHUNKS SSE (explicado abajo)
        })
    )
    .exec(sse("close").close());
```

### ğŸ”„ Procesamiento de Chunks SSE

Este es el **corazÃ³n del sistema**. Se ejecuta cada vez que llegan chunks SSE:

#### **1. InicializaciÃ³n de Variables de SesiÃ³n**

```java
StringBuilder responseContent = new StringBuilder();
final String[] chunkIdHolder = new String[1];
final int[] chunkCounter = new int[1];

// Recuperar timestamp del inicio del request
long requestStartTime = session.contains("requestStartTime")
    ? session.getLong("requestStartTime")
    : System.currentTimeMillis();

// Recuperar contenido acumulado previo
if (session.contains("llmResponse")) {
    responseContent.append(session.getString("llmResponse"));
}

// Recuperar chunk ID previo
if (session.contains("chunkId")) {
    chunkIdHolder[0] = session.getString("chunkId");
}

// Recuperar contador de chunks previo
if (session.contains("chunkCount")) {
    chunkCounter[0] = session.getInt("chunkCount");
}
```

**Nota clave**: Gatling invoca este lambda **mÃºltiples veces por request** (una por batch de chunks), por eso recuperamos el estado previo.

#### **2. Procesamiento de Cada Mensaje SSE**

```java
messages.forEach(message -> {
    String data = message.message();
    if (data != null && !data.isEmpty() && !data.contains("[DONE]")) {
        chunkCounter[0]++; // Incrementar contador

        // Calcular TTFT (solo en el primer chunk con content)
        if (ttftHolder[0] == 0) {
            ttftHolder[0] = System.currentTimeMillis() - requestStartTime;
        }

        // Guardar chunk raw en archivo (debugging)
        Files.writeString(ruta, "ğŸ”¹ SSE chunk: " + data + "\n", APPEND);

        // Parsear JSON del chunk
        JsonObject chunkJson = JsonParser.parseString(data).getAsJsonObject();
        if (chunkJson.has("data")) {
            String innerData = chunkJson.get("data").getAsString();
            JsonObject innerJson = JsonParser.parseString(innerData).getAsJsonObject();

            // Extraer chunk ID (solo la primera vez)
            if (innerJson.has("id") && chunkIdHolder[0] == null) {
                chunkIdHolder[0] = innerJson.get("id").getAsString();
            }

            // Extraer contenido del delta
            if (innerJson.has("choices")) {
                JsonObject choice = innerJson.getAsJsonArray("choices").get(0).getAsJsonObject();
                if (choice.has("delta")) {
                    JsonObject delta = choice.getAsJsonObject("delta");
                    if (delta.has("content")) {
                        String content = delta.get("content").getAsString();
                        responseContent.append(content);
                    }
                }
            }
        }
    }
});
```

#### **3. DetecciÃ³n de FinalizaciÃ³n**

```java
boolean done = messages.stream()
    .anyMatch(m -> m.message().contains("[DONE]"));

// Timeout detection (mÃ¡ximo 10 segundos por request)
long currentTime = System.currentTimeMillis();
long elapsed = currentTime - requestStartTime;
boolean timedOut = elapsed > 10000;

// Finalizar si: (done = true) OR (timeout = true)
if (done || timedOut) {
    // Guardar metadata completa...
}
```

#### **4. ConstrucciÃ³n de Metadata y Guardado**

```java
String fullResponse = responseContent.toString();
long responseTimeMs = currentTime - requestStartTime;

// Obtener informaciÃ³n de la sesiÃ³n
String sessionId = updatedSession.userId() + "-" + updatedSession.scenario();
String category = updatedSession.getString("category");
String prompt = updatedSession.getString("prompt");
// ... mÃ¡s campos del feeder

// Determinar fase del test
long timeSinceTestStart = currentTime - testStartTime;
String testPhase = timeSinceTestStart < rampDuration ? "RAMP" : "STEADY";

// Detectar truncamiento
boolean truncated = timedOut || !done;
String truncationReason = "NONE";
if (timedOut) {
    truncationReason = "TIMEOUT";
}

// Construir ResponseMetadata
ResponseMetadata metadata = ResponseMetadata.builder()
    .sessionId(sessionId)
    .chunkId(storedChunkId)
    .userId(updatedSession.userId())
    .category(category)
    .prompt(prompt)
    .maxTokens(maxTokens)
    .temperature(temperature)
    .response(fullResponse)
    .timestamp(Instant.now())
    .responseTimeMs(responseTimeMs)
    .ttftMs(ttftHolder[0])
    .totalChunks(chunkCounter[0])
    .truncated(truncated)
    .truncationReason(truncationReason)
    .testPhase(testPhase)
    .build();

// Guardar metadata como JSONL (1 lÃ­nea por response)
String jsonLine = objectMapper.writeValueAsString(metadata);
Files.writeString(rutaMetadata, jsonLine + "\n", APPEND);

// TambiÃ©n guardar formato legible (legacy)
Files.writeString(rutaRespuesta, formattedResponse.toString(), APPEND);

// SeÃ±alar a Gatling que terminamos
return updatedSession.set("stop", true);
}
```

### âš™ï¸ ConfiguraciÃ³n de InyecciÃ³n de Carga

```java
setUp(
    prompt.injectOpen(
        rampUsers(10).during(10),         // 0-10s: Subir de 0 a 10 usuarios graduales
        constantUsersPerSec(10).during(60) // 10-70s: Mantener 10 TPS durante 60s
    )
).protocols(httpProtocol);
```

**Resultado**:
- **RAMP phase** (0-10s): ~10 usuarios Ã— ~20 prompts = **~200 requests**
- **STEADY phase** (10-70s): 10 TPS Ã— 60s / ~20 prompts Ã— 20 ejecuciones = **~410 requests**
- **Total**: **~610 requests**

### ğŸ¯ MÃ©tricas Capturadas por SSELLM

| MÃ©trica | CÃ³mo se calcula | Ejemplo |
|---------|----------------|---------|
| **Response Time** | `currentTime - requestStartTime` | 8,826 ms |
| **TTFT** | Timestamp del primer chunk con content - requestStartTime | 320 ms |
| **Total Chunks** | Contador incremental en cada chunk | 42 chunks |
| **Truncated** | `timedOut OR !done` | true |
| **Truncation Reason** | "TIMEOUT" si elapsed > 10s, "NONE" si normal | TIMEOUT |
| **Test Phase** | `timeSinceTestStart < 10s ? "RAMP" : "STEADY"` | STEADY |

### ğŸ“‚ Archivos Generados

1. **`target/responses_metadata.jsonl`** (PRINCIPAL)
   - Formato: JSON Lines (1 objeto JSON por lÃ­nea)
   - Cantidad: 610 lÃ­neas (610 respuestas)
   - Uso: Entrada para ResponseAggregator y ConsistencyAnalyzer

2. **`target/llm_response.txt`** (LEGACY)
   - Formato: Texto plano con separadores
   - PropÃ³sito: Debugging manual, fÃ¡cil de leer

3. **`target/sse_chunks.txt`** (DEBUGGING)
   - Formato: Raw SSE chunks JSON
   - PropÃ³sito: Debugging bajo nivel del protocolo SSE

---

## ğŸ“Š Clase: `ResponseAggregator.java`

**UbicaciÃ³n**: `src/test/java/ssellm/ResponseAggregator.java`

**PropÃ³sito**: Lee el archivo JSONL y agrupa respuestas por diferentes dimensiones para anÃ¡lisis.

### ğŸ” MÃ©todos Principales

#### **1. `readAllResponses() â†’ List<ResponseMetadata>`**

Lee todo el archivo JSONL y deserializa a objetos Java:

```java
public List<ResponseMetadata> readAllResponses() throws IOException {
    if (!Files.exists(metadataFile)) {
        return Collections.emptyList();
    }

    List<ResponseMetadata> responses = new ArrayList<>();
    List<String> lines = Files.readAllLines(metadataFile);

    for (String line : lines) {
        if (line.trim().isEmpty()) continue;

        try {
            ResponseMetadata metadata = objectMapper.readValue(line, ResponseMetadata.class);
            responses.add(metadata);
        } catch (IOException e) {
            System.err.println("âš ï¸ Error parsing line: " + e.getMessage());
        }
    }

    System.out.println("âœ… Loaded " + responses.size() + " responses");
    return responses;
}
```

**Output de ejemplo**:
```
âœ… Loaded 610 responses from target/responses_metadata.jsonl
```

#### **2. `groupByPrompt() â†’ Map<String, List<ResponseMetadata>>`**

Agrupa respuestas que pertenecen al mismo prompt:

```java
public Map<String, List<ResponseMetadata>> groupByPrompt() throws IOException {
    List<ResponseMetadata> allResponses = readAllResponses();

    Map<String, List<ResponseMetadata>> grouped = allResponses.stream()
        .collect(Collectors.groupingBy(ResponseMetadata::getPrompt));

    System.out.println("ğŸ“Š Grouped responses:");
    grouped.forEach((prompt, responses) -> {
        System.out.println("  - \"" + truncate(prompt, 60) + "\" â†’ " + responses.size() + " responses");
    });

    return grouped;
}
```

**Output de ejemplo**:
```
ğŸ“Š Grouped responses:
  - "Explica quÃ© es Java en una oraciÃ³n" â†’ 20 responses
  - "Implementa bÃºsqueda binaria en Java" â†’ 21 responses
  - "PropÃ³n nombres creativos para una startup de IA" â†’ 20 responses
  ...
```

**Uso**: Esencial para anÃ¡lisis de **consistencia semÃ¡ntica** (comparar respuestas del mismo prompt).

#### **3. `groupByCategory() â†’ Map<String, List<ResponseMetadata>>`**

Agrupa por categorÃ­a de prompt (short, medium, long, creative, technical):

```java
public Map<String, List<ResponseMetadata>> groupByCategory() throws IOException {
    List<ResponseMetadata> allResponses = readAllResponses();

    Map<String, List<ResponseMetadata>> grouped = allResponses.stream()
        .collect(Collectors.groupingBy(ResponseMetadata::getCategory));

    return grouped;
}
```

**Output de ejemplo**:
```
ğŸ“Š Grouped by category:
  - short â†’ 84 responses
  - medium â†’ 105 responses
  - long â†’ 81 responses
  - creative â†’ 60 responses
  - technical â†’ 280 responses
```

**Uso**: AnÃ¡lisis de **impacto por categorÃ­a** (Â¿los prompts largos fallan mÃ¡s?).

#### **4. `groupByTestPhase() â†’ Map<String, List<ResponseMetadata>>`**

Agrupa por fase del test (RAMP vs STEADY):

```java
public Map<String, List<ResponseMetadata>> groupByTestPhase() throws IOException {
    List<ResponseMetadata> allResponses = readAllResponses();

    Map<String, List<ResponseMetadata>> grouped = allResponses.stream()
        .collect(Collectors.groupingBy(ResponseMetadata::getTestPhase));

    return grouped;
}
```

**Output de ejemplo**:
```
ğŸ“Š Grouped by test phase:
  - RAMP â†’ 200 responses
  - STEADY â†’ 410 responses
```

**Uso**: AnÃ¡lisis **temporal** (Â¿hay degradaciÃ³n bajo carga sostenida?).

#### **5. `getTruncationStats() â†’ Map<String, Object>`**

Calcula estadÃ­sticas de truncamiento:

```java
public Map<String, Object> getTruncationStats() throws IOException {
    List<ResponseMetadata> allResponses = readAllResponses();

    long totalResponses = allResponses.size();
    long truncatedCount = allResponses.stream()
        .filter(ResponseMetadata::isTruncated)
        .count();

    Map<String, Long> truncationReasons = allResponses.stream()
        .filter(ResponseMetadata::isTruncated)
        .collect(Collectors.groupingBy(
            ResponseMetadata::getTruncationReason,
            Collectors.counting()
        ));

    double truncationRate = (double) truncatedCount / totalResponses;

    Map<String, Object> stats = new HashMap<>();
    stats.put("total_responses", totalResponses);
    stats.put("truncated_count", truncatedCount);
    stats.put("truncation_rate", truncationRate);
    stats.put("truncation_reasons", truncationReasons);

    return stats;
}
```

**Output de ejemplo**:
```
ğŸ“Š Truncation Statistics:
  - Total responses: 610
  - Truncated: 290 (47.50%)
  - Reasons: {TIMEOUT=290}
```

#### **6. `saveGroupedResponses(Path outputFile)`**

Guarda agrupaciÃ³n en formato JSON legible:

```java
public void saveGroupedResponses(Path outputFile) throws IOException {
    Map<String, List<ResponseMetadata>> grouped = groupByPrompt();

    Map<String, Object> output = new HashMap<>();

    for (Map.Entry<String, List<ResponseMetadata>> entry : grouped.entrySet()) {
        String prompt = entry.getKey();
        List<ResponseMetadata> responses = entry.getValue();

        Map<String, Object> promptData = new HashMap<>();
        if (!responses.isEmpty()) {
            ResponseMetadata first = responses.get(0);
            promptData.put("category", first.getCategory());
            promptData.put("max_tokens", first.getMaxTokens());
            promptData.put("temperature", first.getTemperature());
        }
        promptData.put("total_responses", responses.size());
        promptData.put("responses", responses);

        output.put(prompt, promptData);
    }

    ObjectMapper prettyMapper = new ObjectMapper()
        .registerModule(new JavaTimeModule())
        .enable(SerializationFeature.INDENT_OUTPUT);

    String json = prettyMapper.writeValueAsString(output);
    Files.writeString(outputFile, json);

    System.out.println("ğŸ’¾ Grouped responses saved to: " + outputFile);
}
```

**Output**: `target/responses_by_prompt.json`

```json
{
  "Explica quÃ© es Java en una oraciÃ³n": {
    "category": "short",
    "max_tokens": 150,
    "temperature": 0.7,
    "total_responses": 20,
    "responses": [
      { /* ResponseMetadata completo */ },
      { /* ResponseMetadata completo */ }
    ]
  }
}
```

### ğŸš€ EjecuciÃ³n Standalone

```bash
java -cp target/test-classes ssellm.ResponseAggregator
```

Ejecuta todos los mÃ©todos de agregaciÃ³n y guarda `responses_by_prompt.json`.

---

## ğŸ” Clase: `ConsistencyAnalyzer.java`

**UbicaciÃ³n**: `src/test/java/ssellm/ConsistencyAnalyzer.java`

**PropÃ³sito**: Analiza la consistencia de las respuestas sin usar LLM externo, usando **heurÃ­sticas** en 5 dimensiones.

### ğŸ“Š 5 Dimensiones de AnÃ¡lisis

#### **1. Completeness Analysis** (Peso: 25%)

**Pregunta**: Â¿Las respuestas estÃ¡n completas o truncadas?

```java
private Map<String, Object> analyzeCompleteness(List<ResponseMetadata> responses) {
    long truncatedCount = responses.stream()
        .filter(ResponseMetadata::isTruncated)
        .count();

    double completenessScore = 1.0 - ((double) truncatedCount / responses.size());

    Map<String, Long> reasonBreakdown = responses.stream()
        .filter(ResponseMetadata::isTruncated)
        .collect(Collectors.groupingBy(
            ResponseMetadata::getTruncationReason,
            Collectors.counting()
        ));

    // ... construir issues si truncatedCount > 10%
}
```

**MÃ©tricas**:
- **Score**: `1.0 - (truncated / total)`
- **Truncation Rate**: `truncated / total`
- **Issues**: Si > 10% truncadas â†’ severity "high"

**Ejemplo de output**:
```json
{
  "score": 0.525,
  "truncated_count": 290,
  "truncation_rate": 0.475,
  "issues": [
    {
      "description": "290 responses truncated",
      "severity": "high",
      "affected_count": 290,
      "reasons": {"TIMEOUT": 290}
    }
  ]
}
```

#### **2. Structural Analysis** (Peso: 25%)

**Pregunta**: Â¿Las respuestas tienen formato y estructura consistente?

```java
private Map<String, Object> analyzeStructuralConsistency(
    Map<String, List<ResponseMetadata>> byPrompt
) {
    for (Map.Entry<String, List<ResponseMetadata>> entry : byPrompt.entrySet()) {
        List<ResponseMetadata> responses = entry.getValue();
        double promptScore = 1.0;

        // 1. VariaciÃ³n de longitud
        IntSummaryStatistics lengthStats = responses.stream()
            .mapToInt(ResponseMetadata::getResponseLength)
            .summaryStatistics();

        double lengthVariation = (maxLength - minLength) / avgLength;
        if (lengthVariation > 0.5) {  // MÃ¡s del 50% de variaciÃ³n
            promptScore -= 0.1;
            // Agregar issue...
        }

        // 2. Formato Markdown inconsistente
        long markdownCount = responses.stream()
            .filter(r -> containsMarkdown(r.getResponse()))
            .count();

        if (markdownCount > 0 && markdownCount < responses.size()) {
            promptScore -= 0.15;
            // Agregar issue...
        }

        // 3. Mezcla de idiomas
        Map<String, Long> languages = responses.stream()
            .collect(Collectors.groupingBy(
                r -> detectLanguage(r.getResponse()),
                Collectors.counting()
            ));

        if (languages.size() > 1) {
            promptScore -= 0.2;
            // Agregar issue...
        }

        totalScore += Math.max(0.0, promptScore);
    }

    double structuralScore = totalScore / promptCount;
}
```

**HeurÃ­sticas**:
- **Length Variation**: Si (max - min) / avg > 50% â†’ problema
- **Markdown Detection**: `text.contains("```") || text.contains("**")`
- **Language Detection**: Contar palabras comunes en espaÃ±ol vs inglÃ©s

**Ejemplo de output**:
```json
{
  "score": 0.85,
  "issues": [
    {
      "prompt": "Implementa bÃºsqueda binaria...",
      "description": "High length variation: 120.5%",
      "severity": "high",
      "min_length": 50,
      "max_length": 1200,
      "avg_length": 580
    }
  ]
}
```

#### **3. Semantic Analysis** (Peso: 40%)

**Pregunta**: Â¿Las respuestas son semÃ¡nticamente similares entre sÃ­?

**MÃ©todo**: Jaccard Similarity basado en keywords

```java
private Map<String, Object> analyzeSemanticConsistency(
    Map<String, List<ResponseMetadata>> byPrompt
) {
    for (Map.Entry<String, List<ResponseMetadata>> entry : byPrompt.entrySet()) {
        List<ResponseMetadata> responses = entry.getValue();

        // Extraer keywords de todas las respuestas
        List<Set<String>> keywordSets = responses.stream()
            .map(r -> extractKeywords(r.getResponse()))
            .collect(Collectors.toList());

        // Calcular promedio de Jaccard similarity pairwise
        double avgSimilarity = calculateAverageJaccardSimilarity(keywordSets);

        if (avgSimilarity < 0.6) {  // Baja similitud semÃ¡ntica
            // Agregar issue...
        }
    }
}

private Set<String> extractKeywords(String text) {
    Set<String> stopwords = Set.of("the", "is", "are", "and", "el", "la", "de", ...);

    return Pattern.compile("\\w+")
        .matcher(text.toLowerCase())
        .results()
        .map(m -> m.group())
        .filter(word -> word.length() > 3)  // Solo palabras largas
        .filter(word -> !stopwords.contains(word))
        .collect(Collectors.toSet());
}

private double jaccardSimilarity(Set<String> set1, Set<String> set2) {
    Set<String> intersection = new HashSet<>(set1);
    intersection.retainAll(set2);

    Set<String> union = new HashSet<>(set1);
    union.addAll(set2);

    return union.isEmpty() ? 0.0 : (double) intersection.size() / union.size();
}
```

**Proceso**:
1. Extraer keywords (palabras > 3 chars, sin stopwords)
2. Calcular Jaccard similarity entre todos los pares de respuestas
3. Promediar todas las similitudes

**LimitaciÃ³n conocida** (documentada en Sprint 1):
- âš ï¸ **Falsos positivos** en prompts creativos (Jaccard score bajo es esperado)
- âœ… Funciona bien para prompts tÃ©cnicos (cÃ³digo, conceptos)

**Ejemplo de output**:
```json
{
  "score": 0.306,
  "issues": [
    {
      "prompt": "PropÃ³n nombres creativos...",
      "description": "Low semantic similarity between responses",
      "severity": "medium",
      "similarity_score": 0.099,
      "response_count": 20
    }
  ]
}
```

#### **4. Temporal Analysis** (Peso: 5%)

**Pregunta**: Â¿Hay degradaciÃ³n de calidad entre RAMP y STEADY?

```java
private Map<String, Object> analyzeTemporalPatterns(
    Map<String, List<ResponseMetadata>> byPhase
) {
    List<ResponseMetadata> rampPhase = byPhase.get("RAMP");
    List<ResponseMetadata> steadyPhase = byPhase.get("STEADY");

    double rampTruncationRate = calculateTruncationRate(rampPhase);
    double steadyTruncationRate = calculateTruncationRate(steadyPhase);

    double rampAvgResponseTime = calculateAvgResponseTime(rampPhase);
    double steadyAvgResponseTime = calculateAvgResponseTime(steadyPhase);

    double degradation = steadyTruncationRate - rampTruncationRate;
    boolean degradationDetected = degradation > 0.1;  // MÃ¡s de 10% de incremento

    double temporalScore = 1.0 - Math.max(0.0, degradation);

    return Map.of(
        "score", temporalScore,
        "ramp_truncation_rate", rampTruncationRate,
        "steady_truncation_rate", steadyTruncationRate,
        "ramp_avg_response_time_ms", rampAvgResponseTime,
        "steady_avg_response_time_ms", steadyAvgResponseTime,
        "degradation_detected", degradationDetected,
        "degradation_magnitude", degradation
    );
}
```

**MÃ©tricas**:
- Truncation rate: RAMP vs STEADY
- Avg response time: RAMP vs STEADY
- Degradation: `steady_truncation - ramp_truncation`

**Ejemplo de output**:
```json
{
  "score": 0.85,
  "ramp_truncation_rate": 0.05,
  "steady_truncation_rate": 0.52,
  "ramp_avg_response_time_ms": 1009,
  "steady_avg_response_time_ms": 8826,
  "degradation_detected": true,
  "degradation_magnitude": 0.47
}
```

#### **5. Category Analysis** (Peso: 5%)

**Pregunta**: Â¿QuÃ© categorÃ­as de prompts tienen peor calidad?

```java
private Map<String, Object> analyzeCategoryImpact(
    Map<String, List<ResponseMetadata>> byCategory
) {
    Map<String, Map<String, Object>> categoryScores = new HashMap<>();

    for (Map.Entry<String, List<ResponseMetadata>> entry : byCategory.entrySet()) {
        String category = entry.getKey();
        List<ResponseMetadata> responses = entry.getValue();

        double truncationRate = calculateTruncationRate(responses);
        double avgResponseTime = calculateAvgResponseTime(responses);

        Map<String, Object> categoryData = new HashMap<>();
        categoryData.put("response_count", responses.size());
        categoryData.put("truncation_rate", truncationRate);
        categoryData.put("avg_response_time_ms", avgResponseTime);
        categoryData.put("score", 1.0 - truncationRate);

        categoryScores.put(category, categoryData);
    }

    double avgCategoryScore = categoryScores.values().stream()
        .mapToDouble(m -> (double) m.get("score"))
        .average()
        .orElse(1.0);

    return Map.of("categories", categoryScores, "score", avgCategoryScore);
}
```

**Ejemplo de output**:
```json
{
  "score": 0.68,
  "categories": {
    "short": {
      "response_count": 84,
      "truncation_rate": 0.083,
      "avg_response_time_ms": 1250,
      "score": 0.917
    },
    "long": {
      "response_count": 81,
      "truncation_rate": 0.704,
      "avg_response_time_ms": 9200,
      "score": 0.296
    }
  }
}
```

### ğŸ¯ Global Consistency Score

Promedio ponderado de las 5 dimensiones:

```java
private double calculateGlobalScore(Map<String, Object> report) {
    double score =
        completeness.score * 0.25 +  // 25%
        structural.score  * 0.25 +   // 25%
        semantic.score    * 0.40 +   // 40% (mÃ¡s importante)
        temporal.score    * 0.05 +   // 5%
        category.score    * 0.05;    // 5%

    return score;
}
```

**Ejemplo**: Si tenemos:
- Completeness: 0.525
- Structural: 0.85
- Semantic: 0.306
- Temporal: 0.85
- Category: 0.68

```
Global = (0.525 Ã— 0.25) + (0.85 Ã— 0.25) + (0.306 Ã— 0.40) + (0.85 Ã— 0.05) + (0.68 Ã— 0.05)
       = 0.131 + 0.212 + 0.122 + 0.042 + 0.034
       = 0.541 (54.1%)
```

### ğŸ“ Summary Generator

```java
private String generateSummary(Map<String, Object> report) {
    double score = (double) report.get("global_consistency_score");

    StringBuilder summary = new StringBuilder();

    if (score >= 0.90) {
        summary.append("âœ… Excelente consistencia - ");
    } else if (score >= 0.75) {
        summary.append("âš ï¸ Consistencia aceptable - ");
    } else if (score >= 0.60) {
        summary.append("âš ï¸ Consistencia preocupante - ");
    } else {
        summary.append("âŒ Problemas crÃ­ticos de consistencia - ");
    }

    summary.append(String.format("Score global: %.1f%%. ", score * 100));
    // ... mÃ¡s informaciÃ³n contextual

    return summary.toString();
}
```

### ğŸ“‚ Output Final

```java
analyzer.saveReport(report, Path.of("target/consistency_analysis.json"));
```

**Estructura del JSON**:
```json
{
  "analysis_timestamp": "2025-10-26 10:30:00",
  "total_responses": 610,
  "unique_prompts": 30,
  "completeness_analysis": { ... },
  "structural_analysis": { ... },
  "semantic_analysis": { ... },
  "temporal_analysis": { ... },
  "category_analysis": { ... },
  "global_consistency_score": 0.505,
  "summary": "âš ï¸ Consistencia preocupante - Score global: 50.5%. ..."
}
```

### ğŸš€ EjecuciÃ³n Standalone

```bash
java -cp target/test-classes ssellm.ConsistencyAnalyzer
```

---

## ğŸ”„ Flujo de EjecuciÃ³n Completo

### 1ï¸âƒ£ **Ejecutar Load Test**

```bash
export api_key="sk-..."
./mvnw gatling:test
```

**QuÃ© hace**:
- Gatling ejecuta `SSELLM.java`
- Genera 610 requests a OpenAI API
- Captura chunks SSE en tiempo real
- Calcula 16 mÃ©tricas por response
- Guarda en `target/responses_metadata.jsonl`

**Archivos generados**:
- `target/responses_metadata.jsonl` (610 lÃ­neas)
- `target/llm_response.txt` (formato legible)
- `target/sse_chunks.txt` (debugging)
- `target/gatling/...` (reportes HTML de Gatling)

### 2ï¸âƒ£ **Agregar Respuestas**

```bash
java -cp target/test-classes ssellm.ResponseAggregator
```

**QuÃ© hace**:
- Lee `responses_metadata.jsonl`
- Agrupa por: prompt, category, phase
- Calcula estadÃ­sticas de truncamiento
- Guarda en `target/responses_by_prompt.json`

**Output de consola**:
```
âœ… Loaded 610 responses from target/responses_metadata.jsonl
ğŸ“Š Grouped responses:
  - "Explica quÃ© es Java..." â†’ 20 responses
  ...
ğŸ“Š Truncation Statistics:
  - Total responses: 610
  - Truncated: 290 (47.50%)
ğŸ’¾ Grouped responses saved to: target/responses_by_prompt.json
```

### 3ï¸âƒ£ **Analizar Consistencia**

```bash
java -cp target/test-classes ssellm.ConsistencyAnalyzer
```

**QuÃ© hace**:
- Lee `responses_metadata.jsonl`
- Analiza 5 dimensiones de consistencia
- Calcula score global (0-1)
- Genera issues por dimensiÃ³n
- Guarda en `target/consistency_analysis.json`

**Output de consola**:
```
ğŸ” Starting Consistency Analysis...

ğŸ“Š Analyzing completeness...
  âœ“ Completeness score: 0.525
ğŸ“Š Analyzing structural consistency...
  âœ“ Structural score: 0.850
ğŸ“Š Analyzing semantic consistency...
  âœ“ Semantic score: 0.306
ğŸ“Š Analyzing temporal patterns...
  âœ“ Temporal score: 0.850
ğŸ“Š Analyzing category impact...
  âœ“ Category score: 0.680

ğŸ¯ Global Consistency Score: 0.505

âœ… Consistency analysis completed successfully!
ğŸ“Š Report saved to: target/consistency_analysis.json
```

---

## ğŸ“ˆ Ejemplo de Datos Reales (Sprint 1)

### Input: `responses_metadata.jsonl` (610 lÃ­neas)

```jsonl
{"session_id":"1-Scenario","chunk_id":"chatcmpl-xyz","user_id":1,"category":"short","prompt":"Explica quÃ© es Java","max_tokens":150,"temperature":0.7,"response":"Java es un lenguaje...","response_length":245,"timestamp":"2025-10-26T10:15:32.123Z","response_time_ms":1250,"ttft_ms":320,"total_chunks":15,"truncated":false,"truncation_reason":"NONE","test_phase":"STEADY"}
{"session_id":"2-Scenario","chunk_id":"chatcmpl-abc","user_id":2,"category":"long","prompt":"Implementa bÃºsqueda binaria completa con casos edge","max_tokens":800,"temperature":0.7,"response":"```java\npublic class BinarySearch { ... [TRUNCATED]","response_length":3500,"timestamp":"2025-10-26T10:15:42.890Z","response_time_ms":9800,"ttft_ms":450,"total_chunks":42,"truncated":true,"truncation_reason":"TIMEOUT","test_phase":"STEADY"}
...
```

### Output: `consistency_analysis.json`

```json
{
  "analysis_timestamp": "Sat Oct 26 10:30:00 CLT 2025",
  "total_responses": 610,
  "unique_prompts": 30,
  "completeness_analysis": {
    "score": 0.525,
    "truncated_count": 290,
    "truncation_rate": 0.475,
    "issues": [
      {
        "description": "290 responses truncated",
        "severity": "high",
        "affected_count": 290,
        "reasons": {"TIMEOUT": 290}
      }
    ]
  },
  "structural_analysis": {
    "score": 0.850,
    "issues": []
  },
  "semantic_analysis": {
    "score": 0.306,
    "issues": [
      {
        "prompt": "PropÃ³n nombres creativos para una startup de IA",
        "description": "Low semantic similarity between responses",
        "severity": "medium",
        "similarity_score": 0.099,
        "response_count": 20
      }
    ]
  },
  "temporal_analysis": {
    "score": 0.850,
    "ramp_truncation_rate": 0.05,
    "steady_truncation_rate": 0.52,
    "ramp_avg_response_time_ms": 1009,
    "steady_avg_response_time_ms": 8826,
    "degradation_detected": true,
    "degradation_magnitude": 0.47
  },
  "category_analysis": {
    "score": 0.680,
    "categories": {
      "short": {
        "response_count": 84,
        "truncation_rate": 0.083,
        "avg_response_time_ms": 1250,
        "score": 0.917
      },
      "long": {
        "response_count": 81,
        "truncation_rate": 0.704,
        "avg_response_time_ms": 9200,
        "score": 0.296
      }
    }
  },
  "global_consistency_score": 0.505,
  "summary": "âš ï¸ Consistencia preocupante - Score global: 50.5%. Analizadas 610 respuestas. 290 respuestas truncadas. DegradaciÃ³n detectada bajo carga sostenida."
}
```

---

## ğŸ› ï¸ Dependencias del Proyecto

### Maven `pom.xml`

```xml
<!-- Gatling para load testing -->
<dependency>
    <groupId>io.gatling.highcharts</groupId>
    <artifactId>gatling-charts-highcharts</artifactId>
    <version>3.11.3</version>
    <scope>test</scope>
</dependency>

<!-- Jackson para JSON -->
<dependency>
    <groupId>com.fasterxml.jackson.core</groupId>
    <artifactId>jackson-databind</artifactId>
    <version>2.18.0</version>
</dependency>
<dependency>
    <groupId>com.fasterxml.jackson.datatype</groupId>
    <artifactId>jackson-datatype-jsr310</artifactId>
    <version>2.18.0</version>
</dependency>

<!-- Gson para parsing SSE -->
<dependency>
    <groupId>com.google.code.gson</groupId>
    <artifactId>gson</artifactId>
    <version>2.11.0</version>
</dependency>
```

---

## ğŸš€ GuÃ­a de Uso RÃ¡pido

### Ejecutar Test Completo

```bash
# 1. Configurar API key
export api_key="sk-proj-..."

# 2. Ejecutar load test
./mvnw gatling:test

# 3. Agregar respuestas
java -cp target/test-classes ssellm.ResponseAggregator

# 4. Analizar consistencia
java -cp target/test-classes ssellm.ConsistencyAnalyzer

# 5. Ver resultados
cat target/consistency_analysis.json
open target/gatling/*.html  # Reportes Gatling
```

### Ver Archivos Generados

```bash
ls -lh target/

-rw-r--r--  responses_metadata.jsonl   # 610 lÃ­neas JSONL
-rw-r--r--  responses_by_prompt.json   # AgrupaciÃ³n por prompt
-rw-r--r--  consistency_analysis.json  # Reporte final
-rw-r--r--  llm_response.txt          # Formato legible
-rw-r--r--  sse_chunks.txt            # Raw SSE chunks
drwxr-xr-x  gatling/                  # Reportes HTML Gatling
```

---

## ğŸ”® PrÃ³ximos Pasos (Sprint 2-4)

### Sprint 2: AnÃ¡lisis LLM Avanzado
- **LLM-as-a-judge**: Usar GPT-4 para evaluar calidad semÃ¡ntica
- **Prompt engineering**: DiseÃ±ar prompts de evaluaciÃ³n efectivos
- Reemplazar Jaccard similarity con anÃ¡lisis LLM real

### Sprint 3: VisualizaciÃ³n y AutomatizaciÃ³n
- **Dashboard HTML**: GrÃ¡ficos interactivos con Plotly.js
- **Script automatizado**: `run_quality_test.sh` para todo el flujo
- **Umbrales configurables**: YAML con SLAs y alertas

### Sprint 4: ML Avanzado (Opcional)
- **Embeddings vectoriales**: text-embedding-3 para semÃ¡ntica
- **Anomaly detection**: Isolation Forest para outliers
- **Multi-modelo**: Comparar GPT-3.5 vs GPT-4 vs Claude

---

## ğŸ“š Referencias

- **CÃ³digo fuente**: `/src/test/java/ssellm/`
- **DocumentaciÃ³n Sprint 1**: `/docs/sprint1/`
- **ArtÃ­culo de consistencia**: `/docs/sprint1/consistency-article.md`
- **Roadmap**: `/docs/README.md`

---

**Ãšltima actualizaciÃ³n**: Octubre 2025
**Autor**: Ricardo Campos
**Licencia**: MIT
